{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning - Vision\n",
        "### This notebook uses Transfer Learning on a ResNet image recognition base model to be retrained to work on CIFAR-10  \n",
        "### CIFAR-10 is an image recognition dataset with 10 classes:\n",
        "Airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks (lorries)."
      ],
      "metadata": {
        "id": "4vNbN-saGhHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note - It may be best to run this with GPU. Try it with Google Colab's free GPU if needed."
      ],
      "metadata": {
        "id": "L54PXrPfLv61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J6xi95BGDJE"
      },
      "outputs": [],
      "source": [
        "### Run this if needed\n",
        "# !pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n"
      ],
      "metadata": {
        "id": "2HV-L1LbGS55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Set the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "J6jcHfqOGT4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training, we define how each image should be preprocessed.  \n",
        "\n",
        "- **Resize(224Ã—224)**: ResNet was trained on ImageNet images of size 224Ã—224, so we resize our CIFAR-10 images to match.  \n",
        "- **ToTensor()**: Converts the image from a PIL format into a PyTorch tensor so it can be fed into the model.  \n",
        "\n",
        "This preprocessing ensures that our data is in the right format and scale for the ResNet model.  \n"
      ],
      "metadata": {
        "id": "pdWUlr3eidzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),   # Resize images to 224x224 (ResNet expects this)\n",
        "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
        "])\n"
      ],
      "metadata": {
        "id": "Y2FoO5FOGUkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load a **small subset** of the CIFAR-10 dataset for speed.  \n",
        "\n",
        "- Training set: 5,000 images (instead of the full 50,000).  \n",
        "- Test set: 1,000 images (instead of the full 10,000).  \n",
        "\n",
        "This makes the demo much quicker to run while still showing the training process.  \n",
        "We also create **DataLoaders** to handle batching and shuffling.  \n",
        "\n",
        "ðŸ‘‰ CIFAR-10 has 10 classes (airplane, car, bird, etc.), which makes it a good benchmark for image classification.  \n"
      ],
      "metadata": {
        "id": "jkQAeWBiigqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note - decision in next cell - how many samples to use"
      ],
      "metadata": {
        "id": "ypIcFvN3KEev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3: Load a small subset of CIFAR-10 for quick training\n",
        "train_dataset = Subset(\n",
        "    datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform),\n",
        "    range(5000)  # only first 500 images for speed if you want. 5000 will get better accuracy\n",
        ")\n",
        "test_dataset = Subset(\n",
        "    datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform),\n",
        "    range(1000)  # only first 100 images for speed if you want. 1000 is a better test\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "id": "AyKsO3MbGVMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Optional: Show the first training image. Note that CIFAR-10 images are deliberately blurry!\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img, label = train_dataset[0]           # get the first image and label. Change to see a different image\n",
        "img = img.permute(1, 2, 0)              # convert from C x H x W to H x W x C for plotting\n",
        "plt.imshow(img)                          # display the image\n",
        "plt.title(f\"Label: {label}\")             # show the label\n",
        "plt.axis('off')                          # hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7JVe-tCqHCJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load **ResNet18** with pretrained weights from ImageNet.  \n",
        "\n",
        "- ResNet18 is a well-known convolutional neural network.  \n",
        "- Pretrained weights mean it has already learned useful visual features (edges, shapes, textures, etc.) from millions of images.  \n",
        "\n",
        "We will **reuse** this feature extractor instead of training from scratch, which is called **transfer learning**.  \n"
      ],
      "metadata": {
        "id": "tMVOXBmoikBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Load the pre-trained ResNet18 base model\n",
        "# This is the **base model / backbone**: it has been trained on ImageNet\n",
        "model = models.resnet18(pretrained=True)\n"
      ],
      "metadata": {
        "id": "kFj-Ipj1GWcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We freeze all the parameters of ResNet18.  \n",
        "\n",
        "- This means no gradients will be calculated for the backbone.  \n",
        "- Only the new classifier head will be trained.  \n",
        "\n",
        "This is efficient because the model already knows general features; we only need to adapt it to CIFAR-10 classes.  \n"
      ],
      "metadata": {
        "id": "i8Wgl2gdix7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note - decision in next cells - to freeze all backbone (transfer learning) or unfreeze last layer too (fine-tuning)"
      ],
      "metadata": {
        "id": "6aFeThbFJ-Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5: Freeze the backbone so we only train the new head\n",
        "# Freezing the backbone is transfer learning: we reuse pre-trained features\n",
        "#for param in model.parameters():\n",
        "#    param.requires_grad = False  # no gradients computed for these parameters\n"
      ],
      "metadata": {
        "id": "gt2u7TzWGXSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### Step 5 ALTERNATIVE  if higher accuracy wanted, but will run more slowly:\n",
        "for name, param in model.named_parameters():\n",
        "    if \"layer4\" in name or \"fc\" in name:  # fine-tune last ResNet block + head\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "### This allows a layer to be fine-tuned, rather than just the head\n"
      ],
      "metadata": {
        "id": "K8SDZ9m_IGLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet18 was originally trained to classify **1,000 ImageNet classes**.  \n",
        "We replace its final fully connected (fc) layer with a new one for **10 CIFAR-10 classes**.  \n"
      ],
      "metadata": {
        "id": "UrD1nJERi1Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Replace the original ResNet head with a new classifier for our task\n",
        "# This is the **new head** we are training on CIFAR-10\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 has 10 classes\n",
        "model.to(device)  # move the model to GPU or CPU\n"
      ],
      "metadata": {
        "id": "EJVExrlKGX5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use **cross-entropy loss**, the standard choice for multi-class classification.  \n",
        "\n",
        "This function compares the predicted probability distribution (softmax outputs) with the true class labels and penalises incorrect predictions.  \n",
        "\n",
        "\n",
        "We use the **Adam optimiser** to update the model parameters.  \n",
        "\n",
        "Notice that we only pass in **`model.fc.parameters()`**:  \n",
        "- The backbone is frozen, so we only update the new head.  \n",
        "- Learning rate is set to 1e-3, a typical starting value for Adam.  \n"
      ],
      "metadata": {
        "id": "R_9x9XBmi-Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Define the loss function (cross-entropy for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Step 8: Define the optimiser, only updating the head parameters\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "0Kn3BRAwGYg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train the model for a small number of epochs (e.g. 2â€“10).  \n",
        "\n",
        "Each iteration does the following:  \n",
        "1. Load a batch of images and labels.  \n",
        "2. Perform a forward pass through the model.  \n",
        "3. Compute the loss.  \n",
        "4. Backpropagate the gradients.  \n",
        "5. Update the classifier head parameters with Adam.  \n",
        "\n",
        "We also print the **batch loss every 10 batches** and an **epoch summary** at the end.  \n",
        "This helps track training progress and ensures nothing is going wrong.  \n"
      ],
      "metadata": {
        "id": "1gZrJlmDjE8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note - decision in next cell - how many epochs to use"
      ],
      "metadata": {
        "id": "sKT098y_J5zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 9: Training loop (tiny, use 2 epochs for demo. 10 is better)\n",
        "for epoch in range(10):\n",
        "    model.train()  # set model to training mode\n",
        "    running_loss = 0  # accumulate loss per epoch\n",
        "    for i, (images, labels) in enumerate(train_loader): # Enumerating so we can print tracking\n",
        "        images, labels = images.to(device), labels.to(device)  # move data to device\n",
        "        optimizer.zero_grad()          # reset gradients\n",
        "        outputs = model(images)        # forward pass\n",
        "        loss = criterion(outputs, labels)  # compute loss\n",
        "        loss.backward()                # backpropagation\n",
        "        optimizer.step()               # update head parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        # Print batch loss every 10 batches\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss / (i+1):.4f}\")\n",
        "\n",
        "    # Print epoch summary for tracking\n",
        "    print(f\"âœ… Epoch {epoch+1} completed, Average Loss: {running_loss / len(train_loader):.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XuiueZqcGaV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, we evaluate the model on the test subset.  \n",
        "\n",
        "- Set the model to evaluation mode (`model.eval()`).  \n",
        "- Disable gradients (`torch.no_grad()`), since weâ€™re not training.  \n",
        "- Make predictions on each test batch and count how many are correct.  \n"
      ],
      "metadata": {
        "id": "mJueawekjHJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 10: Quick evaluation on the test subset\n",
        "model.eval()  # set model to evaluation mode\n",
        "correct = 0\n",
        "with torch.no_grad():  # no gradients needed for evaluation\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        preds = model(images).argmax(dim=1)  # get predicted class\n",
        "        correct += (preds == labels).sum().item()\n"
      ],
      "metadata": {
        "id": "hWdeCStCGbFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we calculate and print the **test accuracy**  \n",
        "\n",
        "This gives a quick sense of how well our transfer learning worked on CIFAR-10.  \n"
      ],
      "metadata": {
        "id": "1eb5aox7jJ3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 11: Print test accuracy\n",
        "print(\"Test Accuracy:\", correct / len(test_dataset))\n"
      ],
      "metadata": {
        "id": "azB_oshzGcGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your accuracy is low:\n",
        "\n",
        "*   Add more training data in Step 3\n",
        "*   Unfreeze the last layer in Step 5\n",
        "*   Add more epochs (try 10) in Step 9\n",
        "\n"
      ],
      "metadata": {
        "id": "l5VITlFzJkXt"
      }
    }
  ]
}